\section{Introduction}

The optimization and the involved parallelization of code for the simulation of complex mechanical systems is a key-topic in modern computational mechanics. Constantly increasing computing power of high-performance clusters allow for the simulation of large and complex systems. This requires an efficient parallelization approach, where different parallelization paradigms can be of use. \\

In this report the optimization of a finite element code for the simulation of the unsteady heat equation on a two-dimensional disk is investigated. Therefore, first serial optimization is investigated, by evaluating the influence on performance gain of multiple compiler flags. In a next step the serial optimized code is parallelized using a shared memory approach with the OpenMP library and a distributed memory approach, using one-sided parallelization with MPI. For the OpenMP implementation, two different OpenMP directives (critical region and reduction) are compared considering the performance gain. Different scheduling options with various chunk sizes are assessed and a optimum is determined. For the MPI implementation the current partitioning is discussed and possible improvements are presented.

 Both parallelization approaches are discussed by evaluating the runtime, the speed-up and the efficiency for different number of threads / cores. The top speed-ups and efficiencies are determined for three different unstructured meshes, that are associated with three different refinement levels, for both parallelization approaches.  

 This report is structured as follows. In the second chapter \textit{Theory and Methods} are presented, providing a short overview over the problem and presenting the finite element discretization. The \textit{Implementation and Validation} of the presented problem is discussed in chapter 3, where excerpts of the code are show and explained. The results for the coarse mesh are compared to an analytical solution for the problem, to validate the FEM solver. The results of the optimization of the runtime of the code is presented and discussed chapter 4 \textit{Results and Discussion}. Different optimization tequnices and parallelization methods are assessed, determining the optimal number of threads for the OpenMP implementation and the optimal number of cores for the MPI implementation for each mesh.  Finally, this report is closed with a \textit{Conclusion} in which the key-findings are summarized in chapter 5.
